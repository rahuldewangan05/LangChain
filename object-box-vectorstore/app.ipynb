{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for ui\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "## document loader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "## text splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "## embeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "## vector_Store\n",
    "from langchain_objectbox.vectorstores import ObjectBox\n",
    "\n",
    "## for using open-source llm \"GROQ\"\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "## to make prompts to send to llm\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "## stuff chain to interact with llm\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "## retrival chain to fetch relevent document form vector store\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "## for loading environment variable\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading environment variable\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC-ACER\\AppData\\Local\\Temp\\ipykernel_2636\\2646613745.py:3: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  huggingface_embedding=HuggingFaceBgeEmbeddings(\n",
      "d:\\LangChain\\venv12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\LangChain\\venv12\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## load hugging face emedding and groq for llama3\n",
    "groq_Api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "huggingface_embedding=HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 13:19:43.093 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:19:43.278 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\LangChain\\venv12\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-23 13:19:43.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## title of ui\n",
    "st.title(\"ObjectBox VectorStore Demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading llm\n",
    "llm=ChatGroq(groq_api_key=groq_Api_key,model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prompt\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\" \n",
    "    Answer the question based on the povided context only.\n",
    "    Please provide the most accurate response based on the question.\n",
    "    <context>   \n",
    "    {context}\n",
    "    <context>\n",
    "    Questions:{input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vector embedding and vectorStore\n",
    "def vector_embeddings():\n",
    "    if \"vectordb\" not in st.session_state:\n",
    "        st.session_state.loaders=PyPDFDirectoryLoader(\"./us-census\")\n",
    "        st.session_state.docs=st.session_state.loaders.load()\n",
    "        st.session_state.splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "        st.session_state.documnet=st.session_state.splitter.split_documents(documents=st.session_state.docs)\n",
    "        st.session_state.vectodb=ObjectBox.from_documents(documents=st.session_state.documnet, embedding=huggingface_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 13:51:30.261 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.261 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 13:51:30.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "## taking input from user\n",
    "input_prompt=st.text_input(\"Enter your question from Document\")\n",
    "\n",
    "## button to call vector embedding function to load document in vector store\n",
    "if st.button(\"Document Embedding\"):\n",
    "    vector_embeddings()\n",
    "    st.write(\"Document loaded in ObjectBox VerctorStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "## if the input is given calculating time taken by model to respond\n",
    "if input_prompt:\n",
    "    ## making stuff chain and retriever chain when getting input prompt\n",
    "    document_chain=create_stuff_documents_chain(llm=llm,prompt=prompt)\n",
    "    retriver=st.session_state.vectordb.as_retriever()\n",
    "    retriver_chain=create_retrieval_chain(retriver,document_chain)\n",
    "    \n",
    "    ## noting time taken to get response\n",
    "    start=time.process_time()\n",
    "    output=retriver_chain.invoke({\"input\":input_prompt})\n",
    "    print(\"Response time : \",time.process_time()-start)\n",
    "    \n",
    "    st.write(output[\"answer\"])\n",
    "    \n",
    "    ## also displaying the context (relevent document for that response)\n",
    "    with st.expander(\"Document Similarity Search\"):\n",
    "        ## find relevant document\n",
    "        for i,doc in enumerate(output[\"context\"]):\n",
    "            st.write(doc.page_content)\n",
    "            st.write(\"-------------------------------------------------\")\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
